nav:
  - Home:
    - vLLM Spyre Plugin: README.md
    - Getting Started:
      - Installation: getting_started/installation.md
    - Deploying:
      - Docker: deploying/docker.md
      - Kubernetes: deploying/k8s.md
      - Red Hat OpenShift AI: deploying/rhoai.md
    - Examples:
      - Offline Inference: examples/offline_inference
      - Online Inference: examples/online_inference
    - User Guide:
      - Configuration: user_guide/configuration.md
      - Environment Variables: user_guide/env_vars.md
      - Supported Features: user_guide/supported_features.md
      - Supported Models: user_guide/supported_models.md
    - Developer Guide:
      - Contributing: contributing/README.md
      - Continuous Batching:
        - Tests:
          - End-to-End: contributing/continuous_batching/tests/e2e_testing.md
          - Step-by-Step: contributing/continuous_batching/tests/scheduling_inference_steps.md
          - Other Tests: contributing/continuous_batching/tests/other_tests.md

  - Getting Started:
    - Installation: getting_started/installation.md
  - Deploying:
    - Docker: deploying/docker.md
    - Kubernetes: deploying/k8s.md
    - Red Hat OpenShift AI: deploying/rhoai.md
  - User Guide:
    - Configuration: user_guide/configuration.md
    - Environment Variables: user_guide/env_vars.md
    - Supported Features: user_guide/supported_features.md
    - Supported Models: user_guide/supported_models.md
  - Developer Guide:
    - Contributing: contributing/README.md
    - Continuous Batching:
      - Tests:
        - End-to-End: contributing/continuous_batching/tests/e2e_testing.md
        - Step-by-Step: contributing/continuous_batching/tests/scheduling_inference_steps.md
        - Other Tests: contributing/continuous_batching/tests/other_tests.md
