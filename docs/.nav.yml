nav:
  - Home:
    - vLLM Spyre Plugin: README.md
    - Getting Started:
      - Installation: getting_started/installation.md
    - Deploying:
      - Docker: deploying/docker.md
      - Kubernetes: deploying/k8s.md
      - Red Hat OpenShift AI: deploying/rhoai.md
    - Examples:
      - Offline Inference: examples/offline_inference
      - Online Inference: examples/online_inference
    - User Guide:
      - Configuration: user_guide/configuration.md
      - Environment Variables: user_guide/env_vars.md
      - Supported Features: user_guide/supported_features.md
      - Supported Models: user_guide/supported_models.md
    - Developer Guide:
      - Contributing: contributing/README.md

  - Getting Started:
    - Installation: getting_started/installation.md
  - Deploying:
    - Docker: deploying/docker.md
    - Kubernetes: deploying/k8s.md
    - Red Hat OpenShift AI: deploying/rhoai.md
  - User Guide:
    - Configuration: user_guide/configuration.md
    - Environment Variables: user_guide/env_vars.md
    - Supported Features: user_guide/supported_features.md
    - Supported Models: user_guide/supported_models.md
  - Developer Guide:
    - Contributing: contributing/README.md
